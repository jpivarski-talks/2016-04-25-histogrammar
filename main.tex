\documentclass{beamer}
%
% Choose how your presentation looks.
%
% For more themes, color themes and font themes, see:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
%
\mode<presentation>
{
  \usetheme{default}      % or try Darmstadt, Madrid, Warsaw, ...
  \usecolortheme{default} % or try albatross, beaver, crane, ...
  \usefonttheme{default}  % or try serif, structurebold, ...
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
  \setbeamertemplate{footline}[frame number]
} 

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{dirtree}
\usepackage{listings}
\usepackage{courier}

\title[2016-04-25-histogrammar]{Histogramming in map-reduce}
\author{Jim Pivarski}
\institute{Princeton University -- DIANA}
\date{April 25, 2016}

\xdefinecolor{darkblue}{rgb}{0.1,0.1,0.7}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\xdefinecolor{darkgrey}{rgb}{0.35,0.35,0.35}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color
  basicstyle=\ttfamily\small,      % size of fonts used for the code
  breaklines=true,                 % automatic line breaking only at whitespace
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  keywordstyle=\color{blue},       % keyword style
  stringstyle=\color{mymauve},     % string literal style
  showstringspaces=false,
  showlines=true
}

\lstdefinelanguage{scala}{
  morekeywords={abstract,case,catch,class,def,%
    do,else,extends,false,final,finally,%
    for,if,implicit,import,match,mixin,%
    new,null,object,override,package,%
    private,protected,requires,return,sealed,%
    super,this,throw,trait,true,try,%
    type,val,var,while,with,yield},
  otherkeywords={=>,<-,<\%,<:,>:,\#,@},
  sensitive=true,
  morecomment=[l]{//},
  morecomment=[n]{/*}{*/},
  morestring=[b]",
  morestring=[b]',
  morestring=[b]"""
}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

% Uncomment these lines for an automatically generated outline.
%\begin{frame}{Outline}
%  \tableofcontents
%\end{frame}

\begin{frame}{Motivation}
%% ``Motivation started pragmatic, ended up idealistic.''

I'm working with an analysis group (Oliver Gutsche, Matteo Cremonesi, and Cristina Su\'arez) to do a CMS dark matter search using Apache Spark.

\vspace{0.5 cm}
{\it All steps} are to be distributed across the Spark cluster:

\begin{description}
\item[(1)] skim and pull out relevant features;
\item[(2)] exploratory data analysis (EDA);
\item[(3)] final plots.
\end{description}

\uncover<2>{\begin{block}{}
Someday, it may be possible for analysis groups to do all work on a central server, rather than downloaded skims.

\vspace{0.3 cm}
(In some industries, this is already common, especially with SQL.)
\end{block}}
\end{frame}

\begin{frame}{Step (1) is underway}
You may have seen my previous talks on accessing ROOT in Scala (Spark's native language).

\vspace{0.5 cm}
Three different solutions are now in place for testing:

\begin{itemize}
\item bulk convert ROOT $\to$ Avro $\to$ any industry format;
\item read ROOT directly into Scala in a single process using JNI;
\item stream ROOT data through a UNIX pipe into Scala.
\end{itemize}

\vspace{0.5 cm}
They each have different strengths, and we'll pick a favorite in the course of the analysis.
\end{frame}

\begin{frame}[fragile]{Steps (2) and (3): making plots}
As I said, we want to avoid downloading the whole dataset to a laptop for a traditional ntuple-analysis.

\vspace{0.5 cm}
Spark has a functional for reducing data in a distributed way:

\begin{center}
\tt \small RDD.aggregate(initialize)(increment, combine)
\end{center}

where
\begin{itemize}
\item {\tt \small RDD} is a collection of data of type $\mathcal{D}$ (end of skimming chain)
\item {\tt \small initialize} creates a counter of type $\mathcal{C}$
\item {\tt \small increment} is a function from $(\mathcal{C},\mathcal{D}) \to \mathcal{C}$
\item {\tt \small combine} is a function from $(\mathcal{C},\mathcal{C}) \to \mathcal{C}$
\end{itemize}
\end{frame}

\begin{frame}{Aggregate functional}

\begin{center}
\tt \small RDD.aggregate(initialize)(increment, combine)
\end{center}

\vfill
\includegraphics[width=\linewidth]{aggregate.pdf}
\end{frame}

\begin{frame}[fragile]{Histograms fit naturally into aggregate}

\begin{lstlisting}[language=scala]
// hypothetical import ROOT
import org.dianahep.scaroot.classes.TH1F

val finalHist = RDD.aggregate(
    // "booking"
      new TH1F("pt", "pt", 100, 0, 20))(
    // "filling"
      {(h, d) => h.Fill(sqrt(d.px**2 + d.py**2))},
    // "merging"
      {(h1, h2) => h1.Add(h2)})
\end{lstlisting}

\uncover<2>{\begin{block}{}
\vspace{-\baselineskip}
Not bad, but what if you want to fill more than one histogram?

\begin{itemize}
\item These are {\it functions:} all histograms must be passed in as arguments and collected as return values.
\item No global state because Spark is distributed.
\item Data analyst has to maintain histogram code in three places.
\end{itemize}
\end{block}}
\end{frame}

\begin{frame}[fragile]{First idea:}
\textcolor{darkblue}{\large Move the logic of histogram-filling into the booking stage.}

\begin{lstlisting}[language=scala]
val h = Histogram("pt", 100, 0, 20,
                  {d => sqrt(d.px**2 + d.py**2)})
\end{lstlisting}

\hfill ``fill rule:'' $f: \mathcal{D} \to \mathbb{R}$ \hspace{2.1 cm}

\vfill
This more functional design allows the filling and merging to be automatic: no user input required.

\begin{lstlisting}[language=scala]
RDD.aggregate(h)(auto_increment(), auto_combine())
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Second idea:}
\textcolor{darkblue}{\large Collect histograms into a container that also has automated filling and merging.}

\begin{lstlisting}[language=scala]
val pack_o_histograms = Label(
      "pt" -> Histogram(100, 0, 20, fill_pt),
      "Emiss" -> Histogram(100, 0, 50, fill_Emiss),
      ...)

RDD.aggregate(pack_o_histograms)(auto_increment(),
      auto_combine())
\end{lstlisting}

\vfill
({\tt \small Label} shares a superclass with {\tt \small Histogram}; they are called the same way by {\tt \small auto\_increment()} and {\tt \small auto\_combine()}.)
\end{frame}

\begin{frame}[fragile]{Third idea:}
\textcolor{darkblue}{\large Let all of these pieces be composable.}

\begin{lstlisting}[language=scala]
val directories =
      Label("dir1" ->
                Label("pt" -> Histogram(...),
                      "Emiss" -> Histogram(...)),
            "dir2" ->
                Label("pass" -> Count(...),
                      "maxpt" -> Maximize(...)))
\end{lstlisting}

\vspace{0.5 cm}
(Combining directories of histograms is similar to ROOT's {\tt \small hadd}.)
\end{frame}

\begin{frame}[fragile]{}
\textcolor{darkblue}{\large Notice that histograms themselves can be decomposed into smaller pieces:}

\begin{lstlisting}[language=scala]
val histogram = Bin(100, 0, 20, fill_rule, Count())
\end{lstlisting}

where
\begin{itemize}
\item {\tt \small Count} is an aggregator that counts events;
\item {\tt \small Bin} is an aggregator that makes 100 sub-aggregators and uses {\tt \small fill\_rule} to decide which one to pass data on to.
\end{itemize}

\vfill
\begin{uncoverenv}<2->
We get two-dimensional histograms for free:
\begin{lstlisting}[language=scala]
val hist2d = Bin(binsX, lowX, highX, fillX,
                   Bin(binsY, lowY, highY, fillY, Count()))
\end{lstlisting}
\end{uncoverenv}
\vspace{-2 cm}
\end{frame}

\begin{frame}[fragile]{}
With the right sub-aggregators, we can get profile plots:
\begin{lstlisting}[language=scala]
val profile = Bin(binsX, lowX, highX, fillX,
                    Deviate(fillY))
\end{lstlisting}

Box-and-whisker plots:
\begin{lstlisting}[language=scala]
val box_whiskers = Bin(binsX, lowX, highX, fillX,
                         Branch(Quantile(fillY),
                                Minimize(fillY),
                                Maximize(fillY)))
\end{lstlisting}

Heatmaps (average per bin, not 2d histograms):
\begin{lstlisting}[language=scala]
val heatmap = Bin(binsX, lowX, highX, fillX,
                    Bin(binsY, lowY, fillY,
                          Average()))
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{}
\textcolor{darkblue}{\large Mix and match with alternate binning schemes:}

\vspace{0.5 cm}
Fill a hashmap instead of an array:
\begin{lstlisting}[language=scala]
val unknown_support =
      SparselyBin(binWidth, fillX, Count())
\end{lstlisting}

Non-uniform bins:
\begin{lstlisting}[language=scala]
val like_clustering =
      CentrallyBin(binCenters, fillX, Count())
val may_overlap =
      IrregularlyBin(binRanges, fillX, Count())
\end{lstlisting}

Use a clustering algorithm to find bin centers:
\begin{lstlisting}[language=scala]
val first_look = AdaptivelyBin(fillX, Count())

val violin_plot = Bin(binsX, lowX, highX, fillX,
                      AdaptivelyBin(fillY, Count())
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{}
\textcolor{darkblue}{\large Similarly for super-histogram structures:}

\vspace{0.5 cm}
\begin{lstlisting}[language=scala]
val efficiency = Fraction(cut, Histogram(...))
\end{lstlisting}
where {\tt \small cut} is a function from $\mathcal{D} \to$ bool; two identical histograms are booked, one (denominator) is filled with all events, the other (numerator) only if it passes the cut.

\vfill
\begin{lstlisting}[language=scala]
val stack = Stack(q, cuts, Histogram(...))
\end{lstlisting}
where {\tt \small q} is a function from $\mathcal{D} \to \mathbb{R}$ and {\tt \small cuts} are successively tighter thresholds; $N_{\mbox{\scriptsize cuts}} + 1$ histograms are created.

\vfill
\begin{lstlisting}[language=scala]
val partition = Partition(q, cuts, Histogram(...))
\end{lstlisting}
Histograms now represent data {\it between} cuts (think centrality bins in heavy ions).
\end{frame}

\begin{frame}[fragile]{}
\textcolor{darkblue}{\large Categorical features, too:}

\vfill
Fill rule maps from $\mathcal{D} \to$ string:
\begin{lstlisting}[language=scala]
val bar_chart = Categorize(fillType, Count())
\end{lstlisting}
Order of categories on the axis can be imposed {\it after} aggregation. The data are accumulated in a hashmap.

\vfill
\begin{lstlisting}[language=scala]
val backgrounds =
     Categorize({d => d.eventType},
       Histogram(120, 0, 120, {d => d.dimuonMass}))
\end{lstlisting}

Stacking order can also be imposed after aggregation.
\end{frame}

\begin{frame}{}
\textcolor{darkblue}{\large A whole analysis can be a tree of nested histogram primitives with lambda functions at each level.}

\vfill
\dirtree{%
.1 {\tt \small Label}.
.2 {\tt \small "trigger thresholds"}.
.3 {\tt \small Stack} $\to$ {\tt \small Fraction} $\to$ {\tt \small Bin} $\to$ {\tt \small Count}.
.2 {\tt \small "cut scan"}.
.3 {\tt \small Stack} $\to$ {\tt \small Label}.
.4 {\tt \small "a vs b"} $\to$ {\tt \small Bin} $\to$ {\tt \small Deviate}.
.4 {\tt \small "b vs c"} $\to$ {\tt \small Bin} $\to$ {\tt \small Deviate}.
.2 {\tt \small "pT windows"}.
.3 {\tt \small Partition} $\to$ {\tt \small Label}.
.4 {\tt \small "a"} $\to$ {\tt \small Bin} $\to$ {\tt \small Count}.
.4 {\tt \small "b"} $\to$ {\tt \small Bin} $\to$ {\tt \small Count}.
}

\vfill
Can answer questions like, ``which cuts were applied in this plot?'' by walking the tree, rather than scanning a {\tt \small for} loop for {\tt \small break} statements.
\end{frame}

\begin{frame}{Implementation}
Three weeks ago, I started implementing this grammar to see if it can be made coherent.

\begin{center}
\textcolor{blue}{\url{http://github.com/diana-hep/histogrammar/}}
\end{center}

(with an ``a,'' get it?)
\end{frame}

\begin{frame}{}
\vfill
\hspace{-0.5 cm}\begin{minipage}{\linewidth}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l c c | l c c}
Primitive & Scala & Python & Primitive & Scala & Python \\\hline
{\tt \small Count}       & done & done & {\tt \small CentrallyBin}    & done & \\
{\tt \small Sum}         & done & done & {\tt \small AdaptivelyBin}   & done & \\
{\tt \small Average}     & done & done & {\tt \small IrregularlyBin}  &      & \\    
{\tt \small Deviate}     & done & done & {\tt \small Fraction}        & done & \\
{\tt \small AbsoluteErr} & done & done & {\tt \small Stack}           & done & \\
{\tt \small Minimize}    & done & done & {\tt \small Partition}       & done & \\
{\tt \small Maximize}    & done & done & {\tt \small Categorize}      & done & \\
{\tt \small Quantile}    & done &      & {\tt \small Label}           & done & \\
{\tt \small Bag}         & done & done & {\tt \small UntypedLabel}    & done & \\
{\tt \small Bin}         & done & done & {\tt \small Index}           & done & \\
{\tt \small SparselyBin} & done & done & {\tt \small Branch}          & done & \\
\end{tabular}
\end{minipage}

\vfill
Shared JSON representation so primitives can be freely exchanged.

\vfill
Other languages: C++, CUDA?, SQL, R, Javascript (for d3), \ldots
\end{frame}

\begin{frame}[fragile]{Example Spark session}
\begin{lstlisting}[language=scala]
import org.dianahep.histogrammar._
import org.dianahep.histogrammar.histogram._

// declare histograms
val px_histogram = Histogram(100, -5, 5,
  {mu: Muon => mu.px})
val pt_histogram = Histogram(80, 0, 8,
  {mu: Muon => sqrt(mu.px*mu.px + mu.py*mu.py)})
val cut_histogram = Histogram(100, -5, 5,
  {mu: Muon => mu.px}, {mu: Muon => mu.py < 0.0})

// wrap them up in a collection
val all_histograms = Label("px" -> px_histogram,
  "pt" -> pt_histogram, "cut" -> cut_histogram)

// fill them in Spark
val final_histogram = rdd.aggregate(all_histograms)
      (new Increment, new Combine)
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Example Spark session}
\begin{lstlisting}[language=scala]
all_histograms("pt").entries     // 0
final_histogram("pt").entries    // 100000

println(final_histogram("pt").ascii())
\end{lstlisting}
\tiny
\begin{verbatim}
                        0                                                   6616.50
                        +---------------------------------------------------------+
underflow          0    |                                                         |
[  0    ,  0.100)  506  |****                                                     |
[  0.100,  0.200)  1420 |************                                             |
[  0.200,  0.300)  2424 |*********************                                    |
[  0.300,  0.400)  3356 |*****************************                            |
[  0.400,  0.5  )  4258 |*************************************                    |
[  0.5  ,  0.600)  4688 |****************************************                 |
[  0.600,  0.700)  5262 |*********************************************            |
[  0.700,  0.800)  5805 |**************************************************       |
[  0.800,  0.900)  5855 |**************************************************       |
[  0.900,  1    )  6015 |****************************************************     |
[  1    ,  1.10 )  5977 |***************************************************      |
[  1.10 ,  1.20 )  5940 |***************************************************      |
[  1.20 ,  1.30 )  5763 |**************************************************       |
[  1.30 ,  1.40 )  5463 |***********************************************          |
[  1.40 ,  1.5  )  5009 |*******************************************              |
[  1.5  ,  1.60 )  4676 |****************************************                 |
[  1.60 ,  1.70 )  4226 |************************************                     |
[  1.70 ,  1.80 )  3743 |********************************                         |
[  1.80 ,  1.90 )  3226 |****************************                             |
[  1.90 ,  2    )  2911 |*************************                                |
[  2    ,  2.10 )  2449 |*********************                                    |
...
\end{verbatim}
\end{frame}

\begin{frame}{Histogrammar does not produce graphics}
\textcolor{darkblue}{\large (The ASCII art histogram is a placeholder/debugging/fun.)}

\vfill
Although any combination of the primitives can be aggregated and used in an analysis, special combinations like {\tt Bin(Count)} are recognized as plottable.

\vfill
Histogrammar should link to external packages, such as Matplotlib and ROOT, to do actual plotting.
\begin{itemize}
\item Minimal codebase to reimplement in a variety of languages;
\item More of a clearinghouse than a software product, connecting systems that iterate over data to systems that plot data.
\end{itemize}
\end{frame}

\begin{frame}
\vspace{0.3 cm}
\hspace{-0.5 cm}\begin{minipage}{\linewidth}
\tiny
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{p{0.1\linewidth} p{0.9\linewidth}}
Primitive       & Description \\\hline
Count           & Count data, ignoring their content. (Actually a sum of weights.) \\
Sum             & Accumulate the sum of a given quantity. \\
Average         & Accumulate the weighted mean of a given quantity. \\
Deviate         & Accumulate a weighted variance, mean, and total weight of a given quantity (using an algorithm that is stable for large numbers). \\
AbsoluteErr     & Accumulate the weighted Mean Absolute Error (MAE) of a quantity whose nominal value is zero. \\
Minimize        & Find the minimum value of a given quantity. If no data are observed, the result is NaN. \\
Maximize        & Find the maximum value of a given quantity. If no data are observed, the result is NaN. \\
Quantile        & Accumulate an adaptively binned histogram to compute approximate quantiles, such as the median. \\
Bag             & Accumulate raw data up to an optional limit, at which point only the total number is preserved. \\
Bin             & Split a given quantity into equally spaced bins between specified limits and fill only one bin per datum. \\
SparselyBin     & Split a quantity into equally spaced bins, filling only one bin per datum and creating new bins as necessary. \\
CentrallyBin    & Split a quantity into bins defined by a set of bin centers, filling only one datum per bin with no overflows or underflows. \\
AdaptivelyBin   & Split a quanity into bins dynamically with a clustering algorithm, filling only one datum per bin with no overflows or underflows. \\
Fraction        & Accumulate two containers, one with all data (denominator), and one with data that pass a given selection (numerator). \\
Stack           & Accumulate a suite containers, filling all that are above a given cut on a given expression. \\
Partition       & Accumulate a suite containers, filling the one that is between a pair of given cuts on a given expression. \\
Categorize      & Split a given quantity by its categorical (string-based) value and fill only one category per datum. \\
Label           & Accumulate any number of containers of the SAME type and label them with strings. Every one is filled with every input datum. \\
UntypedLabel    & Accumulate containers of any type except Count and label them with strings. Every one is filled with every input datum. \\
Index           & Accumulate any number of containers of the SAME type anonymously in a list. Every one is filled with every input datum. \\
Branch          & Accumulate containers of DIFFERENT types, indexed by i0 through i9. Every one is filled with every input datum. \\
\end{tabular}
\end{minipage}
\end{frame}

\end{document}
